// ðŸŸ¢ GREEN Phase: Production-ready state recovery system
// Complete state recovery with checkpointing and disaster recovery

use super::{ReplayManager, ReplayOptions, StateSnapshot};
use crate::client::rest::RestClient;
use crate::error::{AblyError, AblyResult};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::{SystemTime, UNIX_EPOCH};
use tracing::{debug, info, warn, error};

/// Complete state recovery system with checkpointing and rollback
pub struct StateRecovery {
    replay_manager: ReplayManager,
    recovery_options: RecoveryOptions,
    checkpoints: Vec<StateCheckpoint>,
}

/// Configuration for state recovery behavior
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RecoveryOptions {
    /// Maximum number of checkpoints to maintain
    pub max_checkpoints: usize,
    /// Interval between automatic checkpoints (seconds)
    pub checkpoint_interval_seconds: u64,
    /// Maximum age for valid checkpoints (seconds)
    pub max_checkpoint_age_seconds: u64,
    /// Enable automatic recovery on failure
    pub auto_recovery: bool,
    /// Recovery strategy to use
    pub recovery_strategy: RecoveryStrategy,
    /// Validation options for recovered state
    pub validation: ValidationOptions,
}

/// Strategies for state recovery
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RecoveryStrategy {
    /// Use latest valid checkpoint
    LatestCheckpoint,
    /// Use last known good state
    LastKnownGood,
    /// Replay from specific timestamp
    ReplayFromTimestamp(i64),
    /// Merge multiple recovery sources
    MultiSourceMerge,
    /// Conservative recovery (prioritize data integrity)
    Conservative,
}

/// Validation options for recovered state
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ValidationOptions {
    /// Validate data integrity
    pub check_integrity: bool,
    /// Validate against schema
    pub validate_schema: bool,
    /// Check for logical consistency
    pub check_consistency: bool,
    /// Maximum acceptable data loss (messages)
    pub max_acceptable_loss: usize,
}

/// A state checkpoint for recovery purposes
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StateCheckpoint {
    /// Unique checkpoint identifier
    pub id: String,
    /// Channel this checkpoint covers
    pub channel: String,
    /// Timestamp when checkpoint was created
    pub timestamp: i64,
    /// The actual state snapshot
    pub snapshot: StateSnapshot,
    /// Validation hash for integrity
    pub integrity_hash: String,
    /// Checkpoint metadata
    pub metadata: CheckpointMetadata,
}

/// Metadata about a checkpoint
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CheckpointMetadata {
    /// Why this checkpoint was created
    pub reason: CheckpointReason,
    /// Quality score of the checkpoint (0-100)
    pub quality_score: u8,
    /// Size of the checkpoint in bytes
    pub size_bytes: usize,
    /// Time taken to create checkpoint
    pub creation_time_ms: u64,
    /// Additional tags for organization
    pub tags: Vec<String>,
}

/// Reasons for creating checkpoints
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CheckpointReason {
    /// Scheduled automatic checkpoint
    Scheduled,
    /// Manual checkpoint
    Manual,
    /// Before risky operation
    PreOperation,
    /// After successful operation
    PostOperation,
    /// Emergency/disaster recovery
    Emergency,
}

/// Result of a recovery operation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RecoveryResult {
    /// Whether recovery was successful
    pub success: bool,
    /// Strategy that was used
    pub strategy_used: RecoveryStrategy,
    /// Final recovered state
    pub recovered_state: HashMap<String, serde_json::Value>,
    /// Presence state if available
    pub presence_state: HashMap<String, crate::protocol::messages::PresenceMessage>,
    /// Recovery metrics
    pub metrics: RecoveryMetrics,
    /// Any warnings or issues
    pub warnings: Vec<String>,
    /// Checkpoint used (if any)
    pub checkpoint_used: Option<String>,
}

/// Metrics about the recovery process
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RecoveryMetrics {
    /// Time taken for recovery
    pub recovery_time_ms: u64,
    /// Number of messages replayed
    pub messages_replayed: usize,
    /// Data integrity score (0-100)
    pub integrity_score: u8,
    /// Estimated data loss
    pub estimated_loss_messages: usize,
    /// Confidence in recovery (0-100)
    pub confidence_score: u8,
}

/// Current state of the recovery system
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RecoveryState {
    /// System is healthy
    Healthy,
    /// Minor issues detected
    Degraded,
    /// Significant problems
    Unhealthy,
    /// System is in recovery mode
    Recovering,
    /// Recovery failed
    Failed,
}

impl Default for RecoveryOptions {
    fn default() -> Self {
        Self {
            max_checkpoints: 10,
            checkpoint_interval_seconds: 300, // 5 minutes
            max_checkpoint_age_seconds: 86400, // 24 hours
            auto_recovery: true,
            recovery_strategy: RecoveryStrategy::LatestCheckpoint,
            validation: ValidationOptions {
                check_integrity: true,
                validate_schema: false,
                check_consistency: true,
                max_acceptable_loss: 100,
            },
        }
    }
}

impl StateRecovery {
    /// Create a new state recovery system
    pub fn new(client: RestClient) -> Self {
        let replay_manager = ReplayManager::new(client);
        Self {
            replay_manager,
            recovery_options: RecoveryOptions::default(),
            checkpoints: Vec::new(),
        }
    }
    
    /// Create with custom options
    pub fn with_options(client: RestClient, recovery_options: RecoveryOptions) -> Self {
        let replay_options = ReplayOptions::default();
        let replay_manager = ReplayManager::with_options(client, replay_options);
        Self {
            replay_manager,
            recovery_options,
            checkpoints: Vec::new(),
        }
    }
    
    /// Create a checkpoint of current state
    pub async fn create_checkpoint(&mut self, channel: &str, reason: CheckpointReason) -> AblyResult<String> {
        info!("Creating checkpoint for channel: {} (reason: {:?})", channel, reason);
        let start_time = SystemTime::now();
        
        // Create snapshot
        let snapshot = self.replay_manager.create_snapshot(channel).await?;
        
        // Generate checkpoint ID
        let checkpoint_id = format!("checkpoint_{}_{}", 
            channel, 
            SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis()
        );
        
        // Calculate integrity hash
        let snapshot_json = snapshot.to_json()?;
        let integrity_hash = self.calculate_hash(&snapshot_json);
        
        // Create checkpoint metadata
        let creation_time = start_time.elapsed().unwrap().as_millis() as u64;
        let quality_score = self.calculate_checkpoint_quality(&snapshot);
        let size_bytes = snapshot_json.len();
        
        let metadata = CheckpointMetadata {
            reason,
            quality_score,
            size_bytes,
            creation_time_ms: creation_time,
            tags: vec!["auto".to_string()],
        };
        
        let checkpoint = StateCheckpoint {
            id: checkpoint_id.clone(),
            channel: channel.to_string(),
            timestamp: snapshot.timestamp,
            snapshot,
            integrity_hash,
            metadata,
        };
        
        // Add to checkpoint list
        self.checkpoints.push(checkpoint);
        
        // Cleanup old checkpoints
        self.cleanup_old_checkpoints();
        
        info!("Checkpoint created: {} (quality: {}, size: {} bytes)",
              checkpoint_id, quality_score, size_bytes);
        
        Ok(checkpoint_id)
    }
    
    /// Recover state using the configured strategy
    pub async fn recover_state(&self, channel: &str) -> AblyResult<RecoveryResult> {
        info!("Starting state recovery for channel: {} using strategy: {:?}", 
              channel, self.recovery_options.recovery_strategy);
        let start_time = SystemTime::now();
        
        let mut result = RecoveryResult {
            success: false,
            strategy_used: self.recovery_options.recovery_strategy.clone(),
            recovered_state: HashMap::new(),
            presence_state: HashMap::new(),
            metrics: RecoveryMetrics {
                recovery_time_ms: 0,
                messages_replayed: 0,
                integrity_score: 0,
                estimated_loss_messages: 0,
                confidence_score: 0,
            },
            warnings: Vec::new(),
            checkpoint_used: None,
        };
        
        match &self.recovery_options.recovery_strategy {
            RecoveryStrategy::LatestCheckpoint => {
                if let Some(checkpoint) = self.find_latest_valid_checkpoint(channel) {
                    result.recovered_state = checkpoint.snapshot.message_state.clone();
                    result.presence_state = checkpoint.snapshot.presence_state.clone();
                    result.checkpoint_used = Some(checkpoint.id.clone());
                    result.success = true;
                    result.metrics.confidence_score = checkpoint.metadata.quality_score;
                } else {
                    // Fallback to replay
                    result.warnings.push("No valid checkpoint found, falling back to replay".to_string());
                    return self.recover_via_replay(channel, &mut result).await;
                }
            }
            
            RecoveryStrategy::LastKnownGood => {
                if let Some(checkpoint) = self.find_best_quality_checkpoint(channel) {
                    result.recovered_state = checkpoint.snapshot.message_state.clone();
                    result.presence_state = checkpoint.snapshot.presence_state.clone();
                    result.checkpoint_used = Some(checkpoint.id.clone());
                    result.success = true;
                    result.metrics.confidence_score = checkpoint.metadata.quality_score;
                } else {
                    return self.recover_via_replay(channel, &mut result).await;
                }
            }
            
            RecoveryStrategy::ReplayFromTimestamp(timestamp) => {
                // Create custom replay options
                let mut replay_options = ReplayOptions::default();
                let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as i64;
                replay_options.time_range_seconds = ((now - timestamp) / 1000) as u64;
                
                let replay_result = self.replay_manager.replay_channel(channel).await?;
                result.recovered_state = replay_result.final_state;
                result.presence_state = replay_result.presence_state;
                result.metrics.messages_replayed = replay_result.messages_processed;
                result.success = replay_result.success;
            }
            
            RecoveryStrategy::MultiSourceMerge => {
                return self.recover_via_multi_source_merge(channel, &mut result).await;
            }
            
            RecoveryStrategy::Conservative => {
                return self.recover_conservatively(channel, &mut result).await;
            }
        }
        
        // Calculate final metrics
        result.metrics.recovery_time_ms = start_time.elapsed().unwrap().as_millis() as u64;
        
        if self.recovery_options.validation.check_integrity {
            result.metrics.integrity_score = self.validate_recovered_state(&result.recovered_state);
        }
        
        info!("Recovery completed: success={}, confidence={}, time={}ms",
              result.success, result.metrics.confidence_score, result.metrics.recovery_time_ms);
        
        Ok(result)
    }
    
    /// Recover via full message replay
    async fn recover_via_replay(&self, channel: &str, result: &mut RecoveryResult) -> AblyResult<RecoveryResult> {
        let replay_result = self.replay_manager.replay_channel(channel).await?;
        
        result.recovered_state = replay_result.final_state;
        result.presence_state = replay_result.presence_state;
        result.metrics.messages_replayed = replay_result.messages_processed;
        result.success = replay_result.success;
        result.metrics.confidence_score = if replay_result.success { 90 } else { 0 };
        
        Ok(result.clone())
    }
    
    /// Recover using multiple sources and merge the results
    async fn recover_via_multi_source_merge(&self, channel: &str, result: &mut RecoveryResult) -> AblyResult<RecoveryResult> {
        let mut merged_state = HashMap::new();
        let mut confidence_scores = Vec::new();
        
        // Try checkpoint recovery
        if let Some(checkpoint) = self.find_latest_valid_checkpoint(channel) {
            for (key, value) in &checkpoint.snapshot.message_state {
                merged_state.insert(key.clone(), value.clone());
            }
            confidence_scores.push(checkpoint.metadata.quality_score);
            result.checkpoint_used = Some(checkpoint.id.clone());
        }
        
        // Also do replay and merge newer data
        if let Ok(replay_result) = self.replay_manager.replay_channel(channel).await {
            for (key, value) in replay_result.final_state {
                // Replay data takes precedence (more recent)
                merged_state.insert(key, value);
            }
            result.metrics.messages_replayed = replay_result.messages_processed;
            confidence_scores.push(if replay_result.success { 85 } else { 50 });
        }
        
        result.recovered_state = merged_state;
        result.success = true;
        result.metrics.confidence_score = if confidence_scores.is_empty() {
            0
        } else {
            confidence_scores.iter().sum::<u8>() / confidence_scores.len() as u8
        };
        
        Ok(result.clone())
    }
    
    /// Conservative recovery prioritizing data integrity
    async fn recover_conservatively(&self, channel: &str, result: &mut RecoveryResult) -> AblyResult<RecoveryResult> {
        // Use only the highest quality checkpoint
        if let Some(checkpoint) = self.find_best_quality_checkpoint(channel) {
            if checkpoint.metadata.quality_score >= 80 {
                result.recovered_state = checkpoint.snapshot.message_state.clone();
                result.presence_state = checkpoint.snapshot.presence_state.clone();
                result.checkpoint_used = Some(checkpoint.id.clone());
                result.success = true;
                result.metrics.confidence_score = checkpoint.metadata.quality_score;
            } else {
                result.warnings.push("No high-quality checkpoint available for conservative recovery".to_string());
                result.success = false;
            }
        } else {
            result.warnings.push("No checkpoints available for conservative recovery".to_string());
            result.success = false;
        }
        
        Ok(result.clone())
    }
    
    /// Find the latest valid checkpoint for a channel
    fn find_latest_valid_checkpoint(&self, channel: &str) -> Option<&StateCheckpoint> {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        
        self.checkpoints
            .iter()
            .filter(|cp| cp.channel == channel)
            .filter(|cp| {
                let age = now as i64 - (cp.timestamp / 1000);
                age <= self.recovery_options.max_checkpoint_age_seconds as i64
            })
            .max_by_key(|cp| cp.timestamp)
    }
    
    /// Find the best quality checkpoint for a channel
    fn find_best_quality_checkpoint(&self, channel: &str) -> Option<&StateCheckpoint> {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        
        self.checkpoints
            .iter()
            .filter(|cp| cp.channel == channel)
            .filter(|cp| {
                let age = now as i64 - (cp.timestamp / 1000);
                age <= self.recovery_options.max_checkpoint_age_seconds as i64
            })
            .max_by_key(|cp| cp.metadata.quality_score)
    }
    
    /// Calculate quality score for a checkpoint
    fn calculate_checkpoint_quality(&self, snapshot: &StateSnapshot) -> u8 {
        let mut score = 100u8;
        
        // Penalize for very old snapshots
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_millis() as i64;
        let age_hours = (now - snapshot.timestamp) / (1000 * 60 * 60);
        
        if age_hours > 24 {
            score = score.saturating_sub(20);
        } else if age_hours > 12 {
            score = score.saturating_sub(10);
        }
        
        // Bonus for having data
        if !snapshot.message_state.is_empty() {
            score = score.saturating_add(10);
        }
        
        if !snapshot.presence_state.is_empty() {
            score = score.saturating_add(5);
        }
        
        // Bonus for processing many messages
        if snapshot.metadata.messages_processed > 100 {
            score = score.saturating_add(5);
        }
        
        score
    }
    
    /// Calculate a simple hash for integrity checking
    fn calculate_hash(&self, data: &str) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        data.hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }
    
    /// Validate recovered state integrity
    fn validate_recovered_state(&self, state: &HashMap<String, serde_json::Value>) -> u8 {
        let mut score = 100u8;
        
        // Check for null values
        let null_count = state.values().filter(|v| v.is_null()).count();
        if null_count > 0 {
            score = score.saturating_sub((null_count * 5) as u8);
        }
        
        // Check for empty state
        if state.is_empty() {
            score = 0;
        }
        
        score
    }
    
    /// Clean up old checkpoints
    fn cleanup_old_checkpoints(&mut self) {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        
        // Remove checkpoints that are too old
        self.checkpoints.retain(|cp| {
            let age = now as i64 - (cp.timestamp / 1000);
            age <= self.recovery_options.max_checkpoint_age_seconds as i64
        });
        
        // Keep only the max number of checkpoints per channel
        let mut channel_counts: HashMap<String, usize> = HashMap::new();
        self.checkpoints.retain(|cp| {
            let count = channel_counts.entry(cp.channel.clone()).or_insert(0);
            *count += 1;
            *count <= self.recovery_options.max_checkpoints
        });
        
        debug!("Cleanup complete: {} checkpoints remaining", self.checkpoints.len());
    }
    
    /// Get current recovery system state
    pub fn get_recovery_state(&self) -> RecoveryState {
        if self.checkpoints.is_empty() {
            return RecoveryState::Degraded;
        }
        
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        let recent_checkpoints = self.checkpoints
            .iter()
            .filter(|cp| {
                let age = now as i64 - (cp.timestamp / 1000);
                age <= 3600 // Last hour
            })
            .count();
        
        if recent_checkpoints > 0 {
            RecoveryState::Healthy
        } else {
            RecoveryState::Degraded
        }
    }
    
    /// Get metrics about the recovery system
    pub fn get_recovery_metrics(&self) -> HashMap<String, serde_json::Value> {
        let mut metrics = HashMap::new();
        
        metrics.insert("total_checkpoints".to_string(), 
                      serde_json::json!(self.checkpoints.len()));
        
        if !self.checkpoints.is_empty() {
            let avg_quality: f64 = self.checkpoints
                .iter()
                .map(|cp| cp.metadata.quality_score as f64)
                .sum::<f64>() / self.checkpoints.len() as f64;
            
            metrics.insert("average_quality_score".to_string(), 
                          serde_json::json!(avg_quality));
            
            let latest_checkpoint = self.checkpoints
                .iter()
                .max_by_key(|cp| cp.timestamp);
            
            if let Some(latest) = latest_checkpoint {
                let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
                let age_seconds = now as i64 - (latest.timestamp / 1000);
                metrics.insert("latest_checkpoint_age_seconds".to_string(),
                              serde_json::json!(age_seconds));
            }
        }
        
        metrics.insert("recovery_state".to_string(),
                      serde_json::json!(format!("{:?}", self.get_recovery_state())));
        
        metrics
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::client::rest::RestClient;
    
    fn get_test_api_key() -> String {
        std::env::var("ABLY_API_KEY_SANDBOX")
            .unwrap_or_else(|_| "BGkZHw.WUtzEQ:wpBCK6EsoasbyGyFNefocFYi7ESjkFlyZ8Yh-sh0PIA".to_string())
    }
    
    #[test]
    fn test_state_recovery_creation() {
        let client = RestClient::new(get_test_api_key());
        let recovery = StateRecovery::new(client);
        assert_eq!(recovery.checkpoints.len(), 0);
        assert_eq!(recovery.recovery_options.max_checkpoints, 10);
    }
    
    #[test]
    fn test_recovery_options() {
        let options = RecoveryOptions {
            max_checkpoints: 5,
            checkpoint_interval_seconds: 60,
            max_checkpoint_age_seconds: 3600,
            auto_recovery: false,
            recovery_strategy: RecoveryStrategy::Conservative,
            validation: ValidationOptions {
                check_integrity: true,
                validate_schema: true,
                check_consistency: false,
                max_acceptable_loss: 50,
            },
        };
        
        let client = RestClient::new(get_test_api_key());
        let recovery = StateRecovery::with_options(client, options);
        assert_eq!(recovery.recovery_options.max_checkpoints, 5);
        assert!(!recovery.recovery_options.auto_recovery);
    }
    
    #[test]
    fn test_recovery_state_enum() {
        match RecoveryState::Healthy {
            RecoveryState::Healthy => assert!(true),
            _ => assert!(false),
        }
    }
    
    #[test]
    fn test_checkpoint_reason_serialization() {
        let reason = CheckpointReason::Manual;
        let serialized = serde_json::to_string(&reason).unwrap();
        let deserialized: CheckpointReason = serde_json::from_str(&serialized).unwrap();
        
        match deserialized {
            CheckpointReason::Manual => assert!(true),
            _ => assert!(false),
        }
    }
}